{
  "hash": "7972fe76f94cad2abb78471ae843203a",
  "result": {
    "markdown": "---\ntitle: \"E-commerce 데이터 분석 (2)\"\ndescription: |\n  Data Mart 구성 및 Feature Engineering\ndate: 2023-12-08\ncategories: [machine learning, statistics]\nimage: ecommerce2.png\npreview-links: true\nexecute: \n  cache: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n본 포스팅은 패스트캠퍼스 [50개 프로젝트로 완벽하게 끝내는 머신러닝 시그니쳐](https://fastcampus.co.kr/data_online_msignature)의 강의내용을 바탕으로 참고하여 작성하였습니다.\n\n앞서 [E-commerce 데이터 분석 (1)](https://gwook.blog/blog/2023-12-03-ecommerce-data-analysis/)에서 A사가 운영하는 이커머스 플랫폼의 ②유입 고객 재구매를 촉진시키기 위해 7단계의 문제해결 프로세스를 정의했으며, Step 5의 데이터 분석 단계에 필요한 과정을 진행했습니다.\n\n# 03. Data Mart & Feature Engineering {#sec-3}\n\n## 03-01. Data Mart 기획 및 설계\n\n![모델링을 위한 Data Mart 기획](data-mart.png)\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_08e65167ea0d5663cd79ed091b0ea576'}\n\n:::\n\n\n고객 24,983명에 대한 거래 이력이 총 78만 건 정도였고, 이를 고객 데이터셋을 Undersampling 하여 추출한 분석 대상이 7,495명의 고객 데이터인 상황입니다. UCI Machine Learning Repository의 Online Retail 데이터를 Data Warehouse에서 가져온 데이터이고, 이를 이용해 고객별 구매 이력에 대한 Data Mart를 구성하려고 합니다. 이제 여러 가설을 세워 재구매 여부 `target`에 영향을 미치는 여러 변수(features)를 만들어 보겠습니다. 아래는 Data Mart를 구성하는 여러 feature 에 대한 설명과 로직이 작성되어 있는 Data Mart 기획서입니다.\n\n![Data Mart 기획서](data-mart-desc.png){#fig-1 fig-align=\"center\"}\n\n## 03-02. Data 추출 및 Mart 개발\n\n기본적인 전처리가 끝난 후 데이터를 `df_origin`로 저장되어 있습니다. 샘플링한 표본 데이터를 대상으로 Mart를 구성하기 위해서, 우선 `df_origin`과 표본 데이터 `df_all_sample`에 `bsym`과 `CustomerID`를 조합해 key 변수를 만들어 보겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_3f0299b26986d98aa87994610ac91f05'}\n\n```{.r .cell-code}\ndf_origin %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  InvoiceNo StockCode Description                           Quantity InvoiceDate         UnitPrice CustomerID Country        bsym   \n  <chr>     <chr>     <chr>                                    <int> <dttm>                  <dbl> <chr>      <chr>          <chr>  \n1 489434    85048     \"15CM CHRISTMAS GLASS BALL 20 LIGHTS\"       12 2009-12-01 07:45:00      6.95 13085      United Kingdom 2009-12\n2 489434    79323P    \"PINK CHERRY LIGHTS\"                        12 2009-12-01 07:45:00      6.75 13085      United Kingdom 2009-12\n3 489434    79323W    \"WHITE CHERRY LIGHTS\"                       12 2009-12-01 07:45:00      6.75 13085      United Kingdom 2009-12\n4 489434    22041     \"RECORD FRAME 7\\\" SINGLE SIZE\"              48 2009-12-01 07:45:00      2.1  13085      United Kingdom 2009-12\n5 489434    21232     \"STRAWBERRY CERAMIC TRINKET BOX\"            24 2009-12-01 07:45:00      1.25 13085      United Kingdom 2009-12\n6 489434    22064     \"PINK DOUGHNUT TRINKET POT\"                 24 2009-12-01 07:45:00      1.65 13085      United Kingdom 2009-12\n```\n:::\n\n```{.r .cell-code}\ndf_all_sample %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  bsym    CustomerID target\n  <chr>   <chr>       <dbl>\n1 2009-12 12682           1\n2 2009-12 15413           1\n3 2009-12 16321           0\n4 2009-12 15712           1\n5 2009-12 17700           1\n6 2009-12 14911           1\n```\n:::\n\n```{.r .cell-code}\n# df_origin에 key 변수 생성\ndf_origin <- df_origin %>% \n  mutate(key = str_c(bsym, CustomerID))\ndf_origin %>% \n  reframe(n_key = n_distinct(key))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  n_key\n  <int>\n1 25598\n```\n:::\n\n```{.r .cell-code}\n# df_all_sample에 key 변수 생성\ndf_all_sample <- df_all_sample %>% \n  mutate(key = str_c(bsym, CustomerID))\ndf_all_sample %>% \n  reframe(n_key = n_distinct(key))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  n_key\n  <int>\n1  7495\n```\n:::\n:::\n\n\n이제 `df_origin`의 `key`를 이용해 `df_all_sample`에 존재하는 행들만 가져와 `df_origin_sample` 이라는 데이터를 만듭니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_3093076c4294c5149a459c5425618807'}\n\n```{.r .cell-code}\ndf_origin_sample <- df_origin %>% \n  filter(key %in% df_all_sample$key)\n\n# df_origin과 df_origin_sample의 비율: 대략 30% 정도\nnrow(df_origin_sample)/nrow(df_origin)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2947758\n```\n:::\n:::\n\n\n### Mart 구성 \n\n#### **구매금액**\n\n- Idea: 월별 구매금액에 따라 다음 달 재구매 확률이 다를 것이다\n\nMart 기획서의 첫 번째 **구매금액** 관련 3개의 변수를 만들기 위해 `StockCode` 당 구매금액을 나타내는 변수 `amt`를 `UnitPrice * Quantity`로 정의하겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_d40af0b512c611c1c59f7faad1646fee'}\n\n```{.r .cell-code}\n# 1. 구매금액 amt 관련 변수 , max_amt, min_amt\n## 1) total_amt: 당월 총 구매금액\ndf_mart <- df_origin_sample %>%\n  mutate(amt = UnitPrice * Quantity) %>% \n  group_by(bsym, CustomerID) %>% \n  reframe(total_amt = sum(amt, na.rm = T))\n\n## 2) max_amt, min_amt: 당월 송장당 최대/최소 구매금액\ndf_mart <- df_mart %>% left_join(\n  df_origin_sample %>% \n  mutate(amt = UnitPrice * Quantity) %>% \n  group_by(bsym, CustomerID, InvoiceNo) %>% \n  reframe(amt = sum(amt, na.rm = T)) %>% \n  group_by(bsym, CustomerID) %>% \n  reframe(max_amt = max(amt, na.rm = T),\n          min_amt = min(amt, na.rm = T)),\n  by = c(\"bsym\", \"CustomerID\")\n)\n\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  bsym    CustomerID total_amt max_amt min_amt\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>\n1 2009-12 12437          578.    578.    578. \n2 2009-12 12523           74.6    74.6    74.6\n3 2009-12 12539         5149.   2583.   2566. \n4 2009-12 12557         1953.   1953.   1953. \n5 2009-12 12664          549.    549.    549. \n6 2009-12 12681         1015.   1015.   1015. \n```\n:::\n:::\n\n\n#### **구매건수**\n\n- Idea: 월별 구매건수에 따라 다음 달 재구매 확률이 다를 것이다\n\n이제 구매건수(`cnt`)와 관련된 변수 3가지를 만들겠습니다. 월별 총 구매건수는 `total_cnt`로, 월별 송장(`InvoiceNo`)별 구매 품목 수의 최대/최소는 `max_cnt`, `min_cnt`로 정의하겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_e2af5e531eae8bbec9a6e977b3083b4d'}\n\n```{.r .cell-code}\n# 2. 구매건수 cnt 관련 변수\n## 1) total_cnt: 당월 총 구매건수\ndf_mart <- df_mart %>% left_join(\n  df_origin_sample %>% \n  group_by(bsym, CustomerID) %>% \n  reframe(total_cnt = n_distinct(InvoiceNo)),\n  by = c(\"bsym\", \"CustomerID\")\n)\n## 2) max_cnt, min_cnt: InvoiceNo별 최대/최소 구매 품목 수\ndf_mart <- df_mart %>% \n  left_join(\n    df_origin_sample %>% \n      group_by(bsym, CustomerID, InvoiceNo) %>% \n      reframe(cnt = n_distinct(StockCode)) %>% \n      group_by(bsym, CustomerID) %>% \n      reframe(max_cnt = max(cnt, na.rm = T),\n              min_cnt = min(cnt, na.rm = T)),\n    by = c(\"bsym\", \"CustomerID\")\n  )\n\n\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 8\n  bsym    CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>     <int>   <int>   <int>\n1 2009-12 12437          578.    578.    578.          1      27      27\n2 2009-12 12523           74.6    74.6    74.6         1       4       4\n3 2009-12 12539         5149.   2583.   2566.          2     104     103\n4 2009-12 12557         1953.   1953.   1953.          1       3       3\n5 2009-12 12664          549.    549.    549.          1       4       4\n6 2009-12 12681         1015.   1015.   1015.          1      46      46\n```\n:::\n:::\n\n\n#### **구매수량**\n\n\n- Idea: 월별 구매수량에 따라 다음 달 재구매 확률이 다를 것이다\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_4b6b109fa6b385c66dd1f497b7f0b04e'}\n\n```{.r .cell-code}\n# 3. 구매수량 qty 관련 변수\n## 1) total_qty: 당월 총 구매수량\ndf_mart <- df_mart %>% left_join(\n  df_origin_sample %>% \n    group_by(bsym, CustomerID) %>% \n    reframe(total_qty = sum(Quantity, na.rm = T),\n            max_qty = max(Quantity, na.rm = T),\n            min_qty = min(Quantity, na.rm = T)),\n  by = c(\"bsym\", \"CustomerID\")\n)\n\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 11\n  bsym    CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt total_qty max_qty min_qty\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>     <int>   <int>   <int>     <int>   <int>   <int>\n1 2009-12 12437          578.    578.    578.          1      27      27       263      24       3\n2 2009-12 12523           74.6    74.6    74.6         1       4       4        62      36       4\n3 2009-12 12539         5149.   2583.   2566.          2     104     103      2128      48       2\n4 2009-12 12557         1953.   1953.   1953.          1       3       3       576     216     144\n5 2009-12 12664          549.    549.    549.          1       4       4       134      72       2\n6 2009-12 12681         1015.   1015.   1015.          1      46      46       650      72       1\n```\n:::\n:::\n\n\n\n\n#### **국적**\n\n- Idea: 국적에 따라 재구매 확률이 다를 것이다\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_56eed77e696dcb0946849879b5ea9837'}\n\n```{.r .cell-code}\n# 4. 국적 변수 생성\ndf_mart <- df_mart %>% left_join(\n  df_origin_sample %>% \n    group_by(bsym, CustomerID) %>% \n    reframe(Country = first(Country)),\n  by = c(\"bsym\", \"CustomerID\")\n)\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 12\n  bsym    CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt total_qty max_qty min_qty Country\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>     <int>   <int>   <int>     <int>   <int>   <int> <chr>  \n1 2009-12 12437          578.    578.    578.          1      27      27       263      24       3 France \n2 2009-12 12523           74.6    74.6    74.6         1       4       4        62      36       4 France \n3 2009-12 12539         5149.   2583.   2566.          2     104     103      2128      48       2 Spain  \n4 2009-12 12557         1953.   1953.   1953.          1       3       3       576     216     144 Spain  \n5 2009-12 12664          549.    549.    549.          1       4       4       134      72       2 Finland\n6 2009-12 12681         1015.   1015.   1015.          1      46      46       650      72       1 France \n```\n:::\n:::\n\n\n#### **구매 시간대**\n\n- Idea: 구매 시간대(아침, 점심, 저녁, 밤)에 따라 재구매 확률이 다를 것이다\n\n월별 고객별 아침, 점심, 저녁, 밤에 따른 구매 빈도를 구한 후 가장 많은 시간대를 `peak_time`이라는 이름의 feature로 선택하겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-8_1055e0d43034bc2cea05badd6551e73a'}\n\n```{.r .cell-code}\n# 5. 구매 시간대(아침, 점심, 저녁, 밤)\n## 아침: 6~12시, 점심: 12~18시, 저녁: 18~24시, 밤: 0~6시\n## 시간대별 구매 빈도 계산\ndf_mart <- df_mart %>% left_join(\n  df_origin_sample %>% \n    mutate(hour = hour(InvoiceDate),\n           peak_time = case_when(\n             hour >= 6  & hour < 12 ~ \"Morning\",\n             hour >= 12 & hour < 18 ~ \"Afternoon\",\n             hour >= 18 & hour < 24 ~ \"Evening\",\n             TRUE ~ \"Night\"\n           )) %>% \n    group_by(bsym, CustomerID, peak_time) %>% \n    reframe(purchase_cnt = n()) %>% \n    group_by(bsym, CustomerID) %>% \n    slice_max(purchase_cnt, n = 1, with_ties = FALSE) %>% \n    select(-purchase_cnt) %>% \n    ungroup(),\n  by = c(\"bsym\", \"CustomerID\")\n)\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 13\n  bsym    CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt total_qty max_qty min_qty Country peak_time\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>     <int>   <int>   <int>     <int>   <int>   <int> <chr>   <chr>    \n1 2009-12 12437          578.    578.    578.          1      27      27       263      24       3 France  Afternoon\n2 2009-12 12523           74.6    74.6    74.6         1       4       4        62      36       4 France  Afternoon\n3 2009-12 12539         5149.   2583.   2566.          2     104     103      2128      48       2 Spain   Afternoon\n4 2009-12 12557         1953.   1953.   1953.          1       3       3       576     216     144 Spain   Morning  \n5 2009-12 12664          549.    549.    549.          1       4       4       134      72       2 Finland Morning  \n6 2009-12 12681         1015.   1015.   1015.          1      46      46       650      72       1 France  Afternoon\n```\n:::\n:::\n\n\n#### **계절**\n\n- Idea: 계절에 따라 재구매 확률이 다를 것이다\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-9_66c8b457754285bae871069cb58924c4'}\n\n```{.r .cell-code}\n# 6. 계절 변수 추가\ndf_mart <- df_mart %>% left_join(\n  df_origin_sample %>% \n    mutate(month = month(InvoiceDate),\n           season = case_when(\n             month %in% c(3,4,5) ~ \"Spring\",\n             month %in% c(6,7,8) ~ \"Summer\",\n             month %in% c(9,10,11) ~ \"Autumn\",\n             TRUE ~ \"Winter\"\n           )) %>% \n    group_by(bsym, CustomerID) %>% \n    reframe(season = first(season)),\n  by = c(\"bsym\", \"CustomerID\")\n)\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 14\n  bsym    CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt total_qty max_qty min_qty Country peak_time season\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>     <int>   <int>   <int>     <int>   <int>   <int> <chr>   <chr>     <chr> \n1 2009-12 12437          578.    578.    578.          1      27      27       263      24       3 France  Afternoon Winter\n2 2009-12 12523           74.6    74.6    74.6         1       4       4        62      36       4 France  Afternoon Winter\n3 2009-12 12539         5149.   2583.   2566.          2     104     103      2128      48       2 Spain   Afternoon Winter\n4 2009-12 12557         1953.   1953.   1953.          1       3       3       576     216     144 Spain   Morning   Winter\n5 2009-12 12664          549.    549.    549.          1       4       4       134      72       2 Finland Morning   Winter\n6 2009-12 12681         1015.   1015.   1015.          1      46      46       650      72       1 France  Afternoon Winter\n```\n:::\n:::\n\n\n\n#### **구매 빈도**\n\n- Idea: 구매 빈도가 높은 고객은 재구매 확률이 높을 것이다\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-10_aba2271bf30e5d1f2e906ba33b449e77'}\n\n```{.r .cell-code}\n# 7. 당월 구매 빈도\n## freq = count(InvoiceNo) / # num of days in month\ndf_mart <- df_mart %>% left_join(\n  df_origin_sample %>% \n    group_by(bsym, CustomerID) %>% \n    reframe(cnt = n_distinct(InvoiceNo)) %>% \n    mutate(\n      tmp_date = as.Date(paste0(bsym, \"-01\")),\n      days = as.integer(day(floor_date(tmp_date + months(1), \"month\") - 1)),\n      freq = cnt / days\n    ) %>% \n    select(-c(cnt, tmp_date, days)),\n  by = c(\"bsym\", \"CustomerID\")\n)\n\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 15\n  bsym    CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt total_qty max_qty min_qty Country peak_time season   freq\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>     <int>   <int>   <int>     <int>   <int>   <int> <chr>   <chr>     <chr>   <dbl>\n1 2009-12 12437          578.    578.    578.          1      27      27       263      24       3 France  Afternoon Winter 0.0323\n2 2009-12 12523           74.6    74.6    74.6         1       4       4        62      36       4 France  Afternoon Winter 0.0323\n3 2009-12 12539         5149.   2583.   2566.          2     104     103      2128      48       2 Spain   Afternoon Winter 0.0645\n4 2009-12 12557         1953.   1953.   1953.          1       3       3       576     216     144 Spain   Morning   Winter 0.0323\n5 2009-12 12664          549.    549.    549.          1       4       4       134      72       2 Finland Morning   Winter 0.0323\n6 2009-12 12681         1015.   1015.   1015.          1      46      46       650      72       1 France  Afternoon Winter 0.0323\n```\n:::\n:::\n\n\n#### **평균 구매금액**\n\n- Idea: 평균 구매금액에 따라 재구매 확률이 다를 것이다\n\n이 변수는 단순히 `total_amt`를 `total_cnt`로 나눈 값입니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-11_5d62ff9fd0067af47203d55204e0dab3'}\n\n```{.r .cell-code}\n# 8. 평균 구매금액: avg_amt\n## 송장당 평균 구매금액\ndf_mart <- df_mart %>% \n  mutate(avg_amt = total_amt / total_cnt)\n\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 16\n  bsym    CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt total_qty max_qty min_qty Country peak_time season   freq avg_amt\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>     <int>   <int>   <int>     <int>   <int>   <int> <chr>   <chr>     <chr>   <dbl>   <dbl>\n1 2009-12 12437          578.    578.    578.          1      27      27       263      24       3 France  Afternoon Winter 0.0323   578. \n2 2009-12 12523           74.6    74.6    74.6         1       4       4        62      36       4 France  Afternoon Winter 0.0323    74.6\n3 2009-12 12539         5149.   2583.   2566.          2     104     103      2128      48       2 Spain   Afternoon Winter 0.0645  2575. \n4 2009-12 12557         1953.   1953.   1953.          1       3       3       576     216     144 Spain   Morning   Winter 0.0323  1953. \n5 2009-12 12664          549.    549.    549.          1       4       4       134      72       2 Finland Morning   Winter 0.0323   549. \n6 2009-12 12681         1015.   1015.   1015.          1      46      46       650      72       1 France  Afternoon Winter 0.0323  1015. \n```\n:::\n:::\n\n\n이제 `target` 변수와 병합해 저장하겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-12_d74734dcd10ec473fb2ae0af6f370d9d'}\n\n```{.r .cell-code}\ndf_mart <- df_mart %>% left_join(\n  df_all_sample %>% select(-key),\n  by = c(\"bsym\", \"CustomerID\")\n)\n\ndf_mart %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 17\n  bsym    CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt total_qty max_qty min_qty Country peak_time season   freq avg_amt target\n  <chr>   <chr>          <dbl>   <dbl>   <dbl>     <int>   <int>   <int>     <int>   <int>   <int> <chr>   <chr>     <chr>   <dbl>   <dbl>  <dbl>\n1 2009-12 12437          578.    578.    578.          1      27      27       263      24       3 France  Afternoon Winter 0.0323   578.       1\n2 2009-12 12523           74.6    74.6    74.6         1       4       4        62      36       4 France  Afternoon Winter 0.0323    74.6      0\n3 2009-12 12539         5149.   2583.   2566.          2     104     103      2128      48       2 Spain   Afternoon Winter 0.0645  2575.       0\n4 2009-12 12557         1953.   1953.   1953.          1       3       3       576     216     144 Spain   Morning   Winter 0.0323  1953.       0\n5 2009-12 12664          549.    549.    549.          1       4       4       134      72       2 Finland Morning   Winter 0.0323   549.       0\n6 2009-12 12681         1015.   1015.   1015.          1      46      46       650      72       1 France  Afternoon Winter 0.0323  1015.       1\n```\n:::\n\n```{.r .cell-code}\ndf_mart %>% dim()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7495   17\n```\n:::\n:::\n\n\n\n## 03-03. Numeric Feature Engineering\n\n### Feature Engineering\n\n> Feature Enigneering이란?\n\nFeature들을 재구성하여 모델을 효과적으로 사용하기 쉽게 하는 작업을 말합니다. 즉, 모델링의 성능을 향상시키기 위해 feature를 생성, 선택, 가공하는 일련의 모든 활동을 의미합니다. Feature의 주요한 특징들을 잘 나타낼 수 있도록 변수의 변환, encoding 등의 작업들이 포함됩니다. \n\n때로는 새로운 feature를 생성하기도 하고, 변환(transformation)도 가능합니다. 또한 Feature selection(변수 선택)과 Feature extraction(차원 축소)를 이용하기도 합니다.\n\n현재 저희의 목적은 다음 달 재구매 여부 `target`을 잘 분류하는 모델을 구축하는 Classification 문제에 적합한 feature engineering 과정을 적용하겠습니다.\n\n### Information Value\n\n이진 분류 문제에서 Event(여기서 `target=1`인 경우)와 Non Event의 비율을 고려할 때, 각 비율의 불균형한 정도를 확연하게 보고 싶을 때 사용하는 방법입니다. WoE(Weight of Evidence) 값을 아래와 같이 정의해보겠습니다.\n\n$$ \n\\begin{aligned}\n\\text{WoE} &= \\text{log}\\frac{p}{1-p}\\\\\nwhere\\quad p &= Pr(Event)\n\\end{aligned}\n$$\n\n즉, WoE는 Event 비율의 Odds 값에 로그를 취한 Logit 값입니다. 어떤 Feature의 각 구간(bin)에 대한 (범주형일 경우 각 level) 정보 가치 값은 $$IV_i = (Event_i\\% - NonEvent_i\\%)\\times WoE_i$$으로 표현할 수 있고, 해당 Feature의 정보가치는 이를 모두 더한 $$IV = \\sum IV_i = \\sum\\{(Event_i\\% - NonEvent_i\\%)\\times WoE_i\\}$$ 으로 정의할 수 있습니다.\n\n이러한 feature 별 IV 값에 대한 통상적인 기준은 아래와 같습니다.\n\n![IV 값에 따른 예측력](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FsqkdV%2Fbtr8wPiFwWb%2FB7ugBV1LB50Rjgm6tfU9tK%2Fimg.jpg)\n\n자세한 내용은 [Logistic 예측 모형에서의 변수 선택 방법 - Information Value](https://recipesds.tistory.com/entry/Logistic-%EC%98%88%EC%B8%A1-%EB%AA%A8%ED%98%95%EC%97%90%EC%84%9C%EC%9D%98-%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D-%EB%B0%A9%EB%B2%95-Information-Value)을 참고하시면 됩니다.\n\n이제 앞서 구성한 Data Mart(`df_mart`)의 각 feature에 대해서 IV 값을 구해보겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-13_aaeac970a7512058e812f8acd27c9e67'}\n\n```{.r .cell-code}\ndf_mart %>% \n  reframe(across(everything(), typeof))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 17\n  bsym      CustomerID total_amt max_amt min_amt total_cnt max_cnt min_cnt total_qty max_qty min_qty Country   peak_time season    freq   avg_amt target\n  <chr>     <chr>      <chr>     <chr>   <chr>   <chr>     <chr>   <chr>   <chr>     <chr>   <chr>   <chr>     <chr>     <chr>     <chr>  <chr>   <chr> \n1 character character  double    double  double  integer   integer integer integer   integer integer character character character double double  double\n```\n:::\n:::\n\n\n우선 수치형 변수들에 대해 각각 5% 단위로 binning을 해주고, 40%, 75% 백분위수를 기준으로 3개의 그룹으로 구간화를 시켜주겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-14_da39c9bd6f5419b4b0d930e7b9e34ee9'}\n\n```{.r .cell-code}\niv_calculate <- function(data, var){\n  quant <- quantile(data[[var]], probs = c(0.40, 0.75))\n  iv <- data %>% \n    mutate(grp = findInterval(.data[[var]], quant, rightmost.closed = T) + 1,\n           n_target = ifelse(target==1, 0, 1)) %>% \n    group_by(grp) %>% \n    reframe(\n      target = sum(target, na.rm = T),\n      n_target = sum(n_target, na.rm = T)\n    ) %>% \n    mutate(\n      good_pct = target / sum(target),\n      bad_pct = n_target / sum(n_target),\n      t_ratio = target / (target + n_target),\n      VAR = var,\n      iv = (good_pct - bad_pct) * log(good_pct / bad_pct)\n    ) \n  return(iv)\n}\n\nnumeric_cols <- df_mart %>% select_if(is.numeric) %>% select(-target) %>% colnames()\n\niv_df <- map_dfr(numeric_cols, ~ iv_calculate(df_mart, .x))\nprint(iv_df, n = nrow(iv_df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 × 8\n     grp target n_target good_pct bad_pct t_ratio VAR             iv\n   <dbl>  <dbl>    <dbl>    <dbl>   <dbl>   <dbl> <chr>        <dbl>\n 1     1    853     2145    0.298  0.463    0.285 total_amt 0.0719  \n 2     2    974     1649    0.341  0.356    0.371 total_amt 0.000631\n 3     3   1031      843    0.361  0.182    0.550 total_amt 0.123   \n 4     1    909     2089    0.318  0.451    0.303 max_amt   0.0461  \n 5     2   1015     1608    0.355  0.347    0.387 max_amt   0.000200\n 6     3    934      940    0.327  0.203    0.498 max_amt   0.0593  \n 7     1   1113     1885    0.389  0.407    0.371 min_amt   0.000733\n 8     2   1015     1608    0.355  0.347    0.387 min_amt   0.000200\n 9     3    730     1144    0.255  0.247    0.390 min_amt   0.000302\n10     2   2350     4476    0.822  0.965    0.344 total_cnt 0.0229  \n11     3    508      161    0.178  0.0347   0.759 total_cnt 0.234   \n12     1   1037     1897    0.363  0.409    0.353 max_cnt   0.00555 \n13     2   1059     1675    0.371  0.361    0.387 max_cnt   0.000237\n14     3    762     1065    0.267  0.230    0.417 max_cnt   0.00551 \n15     1   1199     1716    0.420  0.370    0.411 min_cnt   0.00620 \n16     2   1004     1719    0.351  0.371    0.369 min_cnt   0.00104 \n17     3    655     1202    0.229  0.259    0.353 min_cnt   0.00370 \n18     1    886     2104    0.310  0.454    0.296 total_qty 0.0548  \n19     2    985     1647    0.345  0.355    0.374 total_qty 0.000318\n20     3    987      886    0.345  0.191    0.527 total_qty 0.0913  \n21     1    667     1435    0.233  0.309    0.317 max_qty   0.0215  \n22     2   1348     2259    0.472  0.487    0.374 max_qty   0.000502\n23     3    843      943    0.295  0.203    0.472 max_qty   0.0341  \n24     2   2128     3524    0.745  0.760    0.377 min_qty   0.000315\n25     3    730     1113    0.255  0.240    0.396 min_qty   0.000957\n26     2   2081     4195    0.728  0.905    0.332 freq      0.0383  \n27     3    777      442    0.272  0.0953   0.637 freq      0.185   \n28     1    963     2035    0.337  0.439    0.321 avg_amt   0.0269  \n29     2   1030     1593    0.360  0.344    0.393 avg_amt   0.000807\n30     3    865     1009    0.303  0.218    0.462 avg_amt   0.0281  \n```\n:::\n\n```{.r .cell-code}\n# Feature 별 IV 값 합산\niv_df %>% \n  group_by(VAR) %>% \n  reframe(iv = sum(iv)) %>% \n  arrange(desc(iv))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 × 2\n   VAR            iv\n   <chr>       <dbl>\n 1 total_cnt 0.257  \n 2 freq      0.223  \n 3 total_amt 0.195  \n 4 total_qty 0.146  \n 5 max_amt   0.106  \n 6 max_qty   0.0560 \n 7 avg_amt   0.0558 \n 8 max_cnt   0.0113 \n 9 min_cnt   0.0109 \n10 min_qty   0.00127\n11 min_amt   0.00123\n```\n:::\n:::\n\n\n수치형 변수들에 대해서 이렇게 직접 구간(bin)의 경계값을 지정해서 binning을 할 수 있습니다. 이번에는 `target` 변수를 잘 예측하는, 즉 변수별 IV 값이 높게 나오도록 구간화를 하는 방법을 소개하겠습니다. 이러한 방법을 optimized binning이라고 합니다.\n\n`dlookr` 패키지의 `binning_by()` 함수는 반응변수(`target`)을 가장 잘 예측하는 경계값으로 수치형 변수를 binning 하기 때문에 변수별로 bin의 개수가 다를 수 있으며, 수치형 변수가 `target`과 유의한 관계가 없는 경우 구간화를 하지 않아서 변수 선택을 고려할 수도 있습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-15_ef6ca17cc534e236ab93ea948cc59c7e'}\n\n```{.r .cell-code}\nlibrary(dlookr)\nnumeric_cols <- df_mart %>% select_if(is.numeric) %>% select(-target) %>% colnames()\n\n# binning_by() 이용 시 target과 유의하지 않은 변수는 구간화를 하지 않음\nbin_process <- function(data, var){\n  tryCatch({\n    bin <- binning_by(data, target, var)\n    attr(bin, \"name\") <- var\n    return(bin)\n  }, warning = function(w){\n    bin <- \"No significant splits\"\n    attr(bin, \"name\") <- var\n    return(bin)\n  }, error = function(e){\n    bin <- \"Error\"\n    attr(bin, \"name\") <- var\n    return(bin)\n  })\n}\n\nbin_list <- map(numeric_cols, ~bin_process(df_mart, .x))\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-16_7bbc461ab0fbeb140af6b9c6d78cbc0a'}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-17_675123f57d5041dd5b493b9942637266'}\n\n```{.r .cell-code}\n# target과 유의하지 않은 변수 확인:\nbin_list %>% \n  keep(~typeof(.x) == \"character\") %>% \n  map(~attr(.x, \"name\")) %>% \n  unlist()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"min_amt\" \"min_qty\"\n```\n:::\n:::\n\n\n앞서 40%, 75% 백분위수 값을 경계로 IV 값을 구했 때 가장 낮은 IV 값을 가졌던 `min_amt`와 `min_qty`는 최적 구간으로 IV 값을 구했을 경우에도 `target`과 유의하지 않다고 판단되므로 고려하지 않겠습니다.\n\nOptimized binning이 각 수치형 변수의 몇 % 백분위수를 bin의 경계값으로 삼는지 확인해 보겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-18_12f65cddccaa269a245c03efbf131c4b'}\n\n```{.r .cell-code}\nbin_cutoff <- function(data, bin){\n  # cutoff level \n  cutoff <- attr(bin, \"breaks\")\n  grp <- c()\n  for(i in 1:(length(cutoff)-1)){\n    if(i==1){\n      brk <- paste0(\"[\", cutoff[i], \",\", cutoff[i+1], \"]\")\n    } else{\n      brk <- paste0(\"(\", cutoff[i], \",\", cutoff[i+1], \"]\")\n    }\n    grp <- c(grp, brk)\n  }\n  attr(bin, \"levels\") <- grp\n  # data의 수치형변수에서 해당 cutoff가 몇% 백분위수 인지\n  value <- cutoff[2:(length(cutoff)-1)]\n  ecdf_func <- ecdf(data[[attr(bin, \"name\")]])\n  percentile <- ecdf_func(value)\n  return(data.frame(Var = attr(bin, \"name\"), \n                    cutoff = value,\n                    percentile = scales::percent(percentile, accuracy = 2)))\n}\n\nsig_bin_list <- bin_list %>% \n  keep(~typeof(.x) == \"integer\")\n\n# Optimized bin의 경계값 분위수 확인\nsig_bin_list %>% \n  map(~bin_cutoff(df_mart, .x)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n        Var  cutoff percentile\n1 total_amt  138.70        14%\n2 total_amt  219.82        26%\n3 total_amt  542.10        70%\n4 total_amt 1878.72        94%\n\n[[2]]\n      Var  cutoff percentile\n1 max_amt  173.36        20%\n2 max_amt  477.46        72%\n3 max_amt 1136.68        94%\n\n[[3]]\n        Var cutoff percentile\n1 total_cnt      1        74%\n2 total_cnt      2        92%\n\n[[4]]\n      Var cutoff percentile\n1 max_cnt      3         8%\n2 max_cnt     44        86%\n\n[[5]]\n      Var cutoff percentile\n1 min_cnt      4        20%\n2 min_cnt     32        84%\n\n[[6]]\n        Var cutoff percentile\n1 total_qty     95        22%\n2 total_qty    235        58%\n3 total_qty    363        74%\n4 total_qty   1047        94%\n\n[[7]]\n      Var cutoff percentile\n1 max_qty     19        26%\n2 max_qty     90        84%\n3 max_qty    144        94%\n\n[[8]]\n   Var     cutoff percentile\n1 freq 0.03225806        42%\n2 freq 0.03571429        74%\n3 freq 0.07142857        92%\n\n[[9]]\n      Var    cutoff percentile\n1 avg_amt  154.6950        18%\n2 avg_amt  273.6600        44%\n3 avg_amt  521.0000        80%\n4 avg_amt  609.6733        84%\n5 avg_amt 1090.7600        94%\n```\n:::\n\n```{.r .cell-code}\n# Optimized binning 후 IV 값 확인\nsig_bin_list %>% \n  map(~data.frame(name = attr(.x, \"name\"),\n                  IV = attr(.x, \"performance\") %>% pull(IV) %>% .[length(.)])) %>% \n  list_rbind() %>% \n  arrange(desc(IV))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       name      IV\n1 total_cnt 0.36390\n2      freq 0.36390\n3 total_amt 0.28501\n4 total_qty 0.21204\n5   max_amt 0.12493\n6   max_qty 0.08274\n7   avg_amt 0.07401\n8   max_cnt 0.03034\n9   min_cnt 0.01942\n```\n:::\n:::\n\n\n낮은 IV 값을 가졌던 `min_qty`와 `min_amt`를 제외하고 비교해보면, 직접 구간화를 했을 때보다 전반적으로 IV 값들이 높아졌습니다.\n\nBinning 후 각 구간의 분포와 `target`이 1일 때의 분포 그래프를 확인할 수도 있습니다. 아래는 `total_cnt`의 최적 구간화 이후 각 구간별 분포와, `target`이 1인 것의 분포를 나타냅니다.\n\n\n::: {.cell hash='index_cache/html/fig-2_b41a4ae560583addc34df33c93b009e5'}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(patchwork)\ntotal_cnt_bin <- sig_bin_list %>% \n  keep(~attr(.x, \"name\") == \"total_cnt\") %>% .[[1]] \np1 <- total_cnt_bin %>% plot(type = \"freq\") +\n  theme(legend.position = \"none\")\np2 <- total_cnt_bin %>% plot(type = \"posrate\") +\n  theme(legend.position = \"none\")\np1 + p2\n```\n\n::: {.cell-output-display}\n![total_cnt binning 후 분포](index_files/figure-html/fig-2-1.png){#fig-2 width=672}\n:::\n:::\n\n\n\n## 03-03. Categorical Feature Engineering\n\n범주형 변수인 `Country`, `peak_time`, `season`에 대해서도 IV 값을 구해서 `target` 변수와의 관계를 살펴보겠습니다.\n\n우선 국적 변수인 `Country`에 대해 살펴보겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-20_22611fc5ca1de0cd13d4322096233725'}\n\n```{.r .cell-code}\n# 국적 Country 변수 unique한 값 수\ndf_mart %>% \n  reframe(n_uniq = n_distinct(Country))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  n_uniq\n   <int>\n1     33\n```\n:::\n:::\n\n::: {.cell hash='index_cache/html/fig-3_7d78f508cbd4f1a398b4d18d33e423e9'}\n\n```{.r .cell-code  code-fold=\"true\"}\ndf_mart %>% \n  ggplot(aes(x=Country, fill = factor(target))) +\n  geom_bar(position = \"dodge\") +\n  theme_minimal() +\n  coord_flip() +\n  labs(fill = \"Target\", x = \"Country\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![국적별 target 분포](index_files/figure-html/fig-3-1.png){#fig-3 width=672}\n:::\n:::\n\n\n\n@fig-3 을 보면 `Country` 변수의 대부분이 영국(United Kingdom)임을 알 수 있습니다. 따라서 영국을 제외한 나머지 값들은 기타 국가로 변경하겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-22_e4ea7c0844cd9b3de316cb8b7a3c026d'}\n\n```{.r .cell-code}\ndf_mart %>% \n  count(Country) %>% \n  arrange(desc(n)) %>% \n  mutate(ratio = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 33 × 3\n   Country            n   ratio\n   <chr>          <int>   <dbl>\n 1 United Kingdom  6871 0.917  \n 2 Germany          150 0.0200 \n 3 France           144 0.0192 \n 4 Belgium           38 0.00507\n 5 Spain             33 0.00440\n 6 Australia         25 0.00334\n 7 Italy             25 0.00334\n 8 Netherlands       23 0.00307\n 9 Switzerland       23 0.00307\n10 Portugal          22 0.00294\n# ℹ 23 more rows\n```\n:::\n\n```{.r .cell-code}\n# UK 이외의 기타 국가로 처리\ndf_mart <- df_mart %>% \n  mutate(Country = ifelse(Country==\"United Kingdom\", \"UK\", \"ETC\")) \n```\n:::\n\n\n이제 범주형 변수인 `Country`, `peak_time`, `season`의 IV 값을 구해보겠습니다.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-23_4073d5f117e9a58ee18a622dfd00682d'}\n\n```{.r .cell-code}\nlibrary(scorecard)\nCountry_iv <- woebin(df_mart, \"target\", \"Country\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✔ Binning on 7495 rows and 2 columns in 00:00:01\n```\n:::\n\n```{.r .cell-code}\npeak_iv <- woebin(df_mart, \"target\", \"peak_time\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✔ Binning on 7495 rows and 2 columns in 00:00:01\n```\n:::\n\n```{.r .cell-code}\nseason_iv <- woebin(df_mart, \"target\", \"season\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✔ Binning on 7495 rows and 2 columns in 00:00:01\n```\n:::\n\n```{.r .cell-code}\n# Country IV \nCountry_iv$Country %>% tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 12\n  variable bin   count count_distr   neg   pos posprob      woe  bin_iv total_iv\n  <chr>    <chr> <int>       <dbl> <int> <int>   <dbl>    <dbl>   <dbl>    <dbl>\n1 Country  ETC     624      0.0833   387   237   0.380 -6.42e-3 3.43e-6  3.74e-6\n2 Country  UK     6871      0.917   4250  2621   0.381  5.82e-4 3.11e-7  3.74e-6\n# ℹ 2 more variables: breaks <chr>, is_special_values <lgl>\n```\n:::\n\n```{.r .cell-code}\n# peak_time IV\npeak_iv$peak_time %>% tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 12\n  variable  bin   count count_distr   neg   pos posprob     woe  bin_iv total_iv\n  <chr>     <chr> <int>       <dbl> <int> <int>   <dbl>   <dbl>   <dbl>    <dbl>\n1 peak_time Afte…  4845       0.646  3019  1826   0.377 -0.0189 2.29e-4 0.000646\n2 peak_time Morn…  2650       0.354  1618  1032   0.389  0.0343 4.16e-4 0.000646\n# ℹ 2 more variables: breaks <chr>, is_special_values <lgl>\n```\n:::\n\n```{.r .cell-code}\n# season IV\nseason_iv$season %>% tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 12\n  variable bin    count count_distr   neg   pos posprob     woe  bin_iv total_iv\n  <chr>    <chr>  <int>       <dbl> <int> <int>   <dbl>   <dbl>   <dbl>    <dbl>\n1 season   Autumn  2563       0.342  1616   947   0.369 -0.0505 8.65e-4  0.00350\n2 season   Sprin…  3206       0.428  1996  1210   0.377 -0.0166 1.17e-4  0.00350\n3 season   Summer  1726       0.230  1025   701   0.406  0.104  2.52e-3  0.00350\n# ℹ 2 more variables: breaks <chr>, is_special_values <lgl>\n```\n:::\n:::\n\n\n`target` 변수에 대한 범주형 변수들의 IV 값을 보면 굉장히 낮으므로 이 세 변수는 `target` 변수와 유의미한 관계가 없어 보입니다. \n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}