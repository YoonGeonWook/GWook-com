---
title: "E-commerce 데이터 분석 (1)"
description: |
  UCI Machine Learning Repository: Online Retail Dataset
date: 2023-12-03
categories: [machine learning, statistics]
image: ecommerce.jpg
preview-links: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set()
options(width=200)
```

```{css, echo=FALSE}
pre code, pre, code {
  <!-- white-space: pre !important; -->
  overflow-x: scroll !important;
  <!-- word-break: keep-all !important; -->
  <!-- word-wrap: initial !important; -->
}
```

본 포스팅은 패스트캠퍼스 [50개 프로젝트로 완벽하게 끝내는 머신러닝 시그니쳐](https://fastcampus.co.kr/data_online_msignature)의 강의내용을 바탕으로 참고하여 작성하였습니다.

![문제해결 프로세스 7단계](seven-step-problem-solving-process.png){#fig-1}

# 01. 문제해결 프로세스 기획 {#sec-1}

패스트캠퍼스 강의 중 박지환 강사님께서 준비 해주신 이커머스 데이터 분석 예제를 참고하여 진행하였습니다. 주어진 문제의 시나리오는 아래와 같습니다.

::: {.callout-note icon="false"}
### 시나리오

A사는 이커머스 플랫폼을 운영하고 있다. 해당 이커머스 플랫폼 서비스가 성장하기 위해서는 3가지 조건이 필요하다.

① 신규고객 유입 ② 유입 고객 재구매 ③ 재구매고객 충성 고객화

A사는 현재 '① 신규교객 유입 활동'은 마케팅 비용을 투자하여 적극 수행하고 있으나, '② 유입 고객 재구매'이 미미한 상황이다. 충성고객의 Spending Power는 전체 매출에서 많은 비중을 차지하고 있으므로, 충성고객의 성장이 이어지지 않으면 플랫폼의 성장도 멈추게 되버린다.

따라서 '② 유입 고객 재구매'를 촉진시킬 방법을 고민 중에 있는 상황이다.
:::

이 시나리오를 기반으로 문제해결 프로세스 @fig-1 에 따라 7가지 단계를 아래와 같이 정의할 수 있습니다.

::: {.callout-note icon="false"}
### 문제해결 프로세스

#### Step 1. 문제정의

-   문제현상: 신규 고객 유입 후 재구매로 이어지는 고객의 감소
-   예상 피해: `(재구매고객 → 충성고객)`의 부진으로 매출 성장 정체 및 신규고객 유입을 위한 마케팅 비용 증가로 인한 영업이익 감소

#### Step 2. 기대효과

-   재구매 고객 증가 → 충성 고객 증가 → 매출 성장 → 영업 이익 증가
-   선순환 체계 구축으로 인한 서비스 성장

#### Step 3. 해결방안

-   ① EDA 및 일회성 데이터 분석을 통해 재구매 고객의 특성을 분석하고 이를 토대로 마케팅 기획
-   ② 재구매 가능성이 높은 고객을 예측하는 모델링 후 이를 활용한 타겟 마케팅 진행

#### Step 4. 우선순위

-   ①번을 빠르게 수행 후 파일럿 테스트 진행 및 성과 측정
-   ①번의 효과가 좋지 않다면, ②번 진행 후 파일럿 테스트 재실행

#### Step 5. 데이터 분석

-   결정된 우선순위에 따라서 데이터 분석 및 모델링 진행

#### Step 6. 성과측정

-   최종 마케팅 후 성능을 평가하기 위한 지표 수립
-   분석 및 모델링을 통해 추출한 타겟 고객군과 대조군을 설정하여 A/B 테스트 수행
-   A/B 테스트 결과 마케팅(재구매) 반응률 비교를 통해 통계적으로 유의미한지 검증: `t-test`
-   유의미한 결과를 얻을 때까지 파일럿 테스트를 수정하며 진행

#### Step 7. 모델 운영

-   파일럿 테스트 후 결과가 유의미하다면 정규 마케팅으로 운영하기 위한 작업 준비
-   모델을 실행을 위한 주기와 추출 타겟 고객군의 범위 결정
-   정해진 주기에 따라 타겟 고객군의 추출을 자동화
-   이를 마케팅 시스템과 연계하여 타겟 마케팅을 주기적으로 운영 및 평가
:::

현재 Step 1\~4의 단계가 완료되어 **데이터 분석을 수행**해야 하는 단계라고 간주하겠습니다.

# 02. Data Readiness Check & Sampling {#sec-2}

사용하고자 하는 데이터는 [UCI Machine Learning Repository](https://archive.ics.uci.edu/)에서 제공하는 [Online Retail](https://archive.ics.uci.edu/datasets?search=Online+Retail) 데이터를 사용해 진행했습니다.

이 Online Retail 데이터를 A사에서 수집한 고객 거래 이력 데이터로 간주하고 해당 데이터에 대한 기본적인 전처리를 수행하겠습니다.

## 02-01. Data Info Check

주어진 데이터는 e-commerce 온라인 구매 데이터로 데이터 명세표는 아래와 같습니다.

| `InvoiceNo` | `StockCode` | `Description` | `Quantity` | `InvoiceDate` | `UnitPrice` | `CustomerID` |  `Country`  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
|  송장번호   |  재고코드   |   상세설명    |    수량    |   송장날짜    |  개당가격   |    고객ID    |    국가     |
| Categorical | Categorical |  Categorical  |  Integer   |     Date      | Continuous  | Categorical  | Categorical |

이제 수집된 데이터의 기본적인 정보를 확인해 보겠습니다.

```{r}
#| message: false
library(tidyverse)
df <- read_csv("Online Retail.csv", col_types = "ccciTdcc")
df %>% head()
```

#### **Data 크기 확인**

```{r}
# 1,067,370 rows & 8 cols
df %>% dim()
```

#### **Data type 확인**

```{r}
df %>% glimpse()
```

#### **변수별 결측치 확인**

```{r}
df %>% is.na() %>% colSums()
```

고객 식별 정보인 `CustomerID` 같은 변수에 결측치가 있는 경우에는 추후에 해당 고객에 대한 정보를 알 수 없으므로 사전에 정보를 알 수 없는 불분명한 데이터로 취급하여 삭제하는 것이 좋습니다.

```{r}
df <- df %>% drop_na("CustomerID")
df %>% is.na() %>% colSums()
```

#### **Outlier 확인**

```{r}
df %>% 
  select_if(is.numeric) %>% 
  summary()
```

구매 수량을 나타내는 `Quantity`는 음수 값을 가질 수 없으나, 반품 물품에 대한 값이 있으므로 확인 후 처리해야 합니다. 여기서는 `Quantity`가 음수인 값은 이상치(Outlier)라고 간주하고 삭제하겠습니다.

```{r}
# Quantity가 음수인 데이터 확인 
# 반품 및 회수 물량일 수도 있음
df %>% filter(Quantity < 0)
```

```{r}
# Quantity 음수값 제거
df <- df %>% filter(Quantity > 0)
```

#### **중복 데이터 확인**

```{r}
df %>% 
  mutate(duplicated = duplicated(.)) %>% 
  count(duplicated)

# 중복 데이터 확인
df %>% 
  filter(duplicated(df) | duplicated(df, fromLast = TRUE))
```

26,125개의 데이터가 중복되었음을 확인할 수 있습니다. 데이터의 정확성과 품질을 위해 중복 데이터를 삭제하겠습니다.

```{r}
# 중복 삭제 후 재확인
df <- df %>% distinct()
df %>% 
  mutate(duplicated = duplicated(.)) %>% 
  count()
```

이렇게 데이터에 대한 기본적인 정보와 전처리를 마치고 데이터의 형태를 보면 아래와 같이 기존 1,067,370개의 행에서 779,494개의 행으로 줄었습니다.

```{r}
# 1,067,370 → 779,494
df %>% dim()
```

## 02-03. Data Readiness Check

데이터에 대한 기본 정보를 확인했으니 이제 현재 가지고 있는 데이터로 앞서 기획한 문제해결 프로세스를 적용할 수 있는지 점검해야 합니다.

### (1) Target Label 생성

당월 구매 고객이 다음 달에 재구매 시 해당 고객을 재구매 고객으로 정의하겠습니다. 예를들어, 2011년 01월에 구매한 고객이 2011년 02월에 구매를 한다면 해당 고객을 재구매 고객으로 정의하는 것입니다.

```{r}
library(lubridate)

# 기준년월 변수 생성: bsym - %Y-%m 형식
df <- df %>% mutate(bsym = format(InvoiceDate, "%Y-%m")) 
# 원본 데이터 저장: df_origin
df_origin <- df
# 데이터 적재 기간 확인: 2009-12-01 ~ 2011-12-09 (약 2년)
min(df$InvoiceDate); max(df$InvoiceDate)
```

기본적인 전처리가 완료된 데이터를 `df_origin`으로 저장하여 보존하고, 이후 있을 전처리를 진행하겠습니다. Target label은 기준년월(`bsym`)과 고객(`CustomerID`)에만 영향을 받으므로 해당 두 변수를 고유하게 갖는 데이터로 재구성하겠습니다.

```{r}
df <- df %>% distinct(bsym, CustomerID)
df %>% dim()
df %>% head()
```

2009년 12월부터 2011년 12월까지 연도 및 월(`bsym`)별로 당월 구매 고객이 내월 구매 고객일 경우 1을 갖는 `target` 변수(binary: 0,1)를 만들어 보겠습니다.

```{r}
# 주어진 bsym에 구매 고객이 내월 구매 고객일 경우 1, 그렇지 않으면 0 값을 갖는 
# target 변수 생성: process_bsym()
process_bsym <- function(bsym_value, df) {
  df_left <- filter(df, bsym == bsym_value)
  bsym_1m <- ymd(paste0(bsym_value, "-01")) %m+% months(1) %>% format("%Y-%m")
  df_right <- df %>% 
    filter(bsym == bsym_1m) %>% 
    distinct(CustomerID) %>% 
    mutate(target = 1)
  
  df_merge <- left_join(df_left, df_right, by = "CustomerID") %>% 
    mutate(target = ifelse(is.na(target), 0, target))
  
  return(df_merge)
}

# 모든 bsym 값에 대해 process_bsym 함수 적용
df_all <- map_df(unique(df$bsym), ~process_bsym(.x, df))
df_all %>% head()
```

### (2) Target Ratio 확인

연도 및 월별로 재구매 고객 여부 변수 `target`의 비율을 확인해 보겠습니다.

```{r}
# 기준년월 기준 Target ratio 확인
options(pillar.sigfig = 6)
df_target <- df_all %>% 
  group_by(bsym) %>% 
  reframe(total_y = sum(target),
          count_y = n(),
          ratio = total_y/count_y) 
df_target %>% 
  print(n =  nrow(.))
```

현재 주어진 데이터는 2011년 12월이 마지막이기 때문에 내월이 없는 2011년 12월은 `target` 변수가 1 값을 가질 수 없습니다. 따라서 분석 대상에서 제외시키겠습니다.

```{r}
df_target <- df_target %>% filter(bsym != '2011-12')
df_all <- df_all %>% filter(bsym != '2011-12')
df_target %>% 
  print(n = nrow(.))
df_target$ratio %>% summary()
```

연도 및 월(`bsym`)별 `target`의 비율은 22.3% \~ 45.6%의 값을 가지며, 대부분의 월에서 36% \~ 40% 정도의 비율을 갖습니다. 전체 데이터의 `target`의 비율을 보면 아래와 같이 약 37.5% 정도의 내달 재구매 비율을 갖습니다. 이 정도의 class imbalance에 대해서는 over-sampling을 하지 않고 분석을 진행해도 괜찮을 것 같습니다.

```{r}
df_all$target %>% mean()
```

```{r}
# 마지막 행에 합계 추가
df_target <- df_target %>% 
  bind_rows(
    tibble(bsym = "total",
           total_y = sum(.$total_y),
           count_y = sum(.$count_y),
           ratio = 1)  
)
```

## 02-03. Data Sampling

![층화추출법](stratified-sampling.png){#fig-2}

현재 `df_all`에는 약 25,000건의 데이터가 있지만, 만일 데이터가 1억건 정도로 매우 큰 경우 모델링을 하기엔 부담스러울 수 있습니다. 이럴 경우를 대비해 해당 데이터를 모집단으로 간주하고 샘플링을 통해 데이터를 줄일 수 있습니다.

### Under-sampling: Stratified sampling

관심 변수(`target`)에 대해 함께 살펴보고 싶은 변수가 있을 시(여기선 `bsym`), 해당 변수를 층화 변수로 두어 층화추출법(stratified sampling)을 실시할 수 있습니다. 샘플링 기법 중 하나인 층화추출법은 모집단을 층화 변수로 나눈 후 각 층/소집단 별로 독립적으로 표본을 뽑는 샘플링 방법입니다. 이로 인해 모집단 데이터에서 층화 변수와 관심 변수가 갖는 관계를 표본 데이터에서도 유지할 수 있다는 장점이 있습니다. 즉, 표본의 대표성을 확보할 수 있는 방법입니다.

현재 `df_all` 데이터를 모집단 데이터로 간주하고, 표본 데이터를 뽑고자 합니다. 이때 층화추출법을 사용하기 위해선 우선적으로 각 층(`bsym`)별 표본 크기가 주어져야 합니다. 이 과정을 표본 배분(sample allocation)이라고 합니다. 여기에서는 모집단 `df_all`의 `bsym`별 층 크기를 유지하기 위해 비례 배분(proportional allocation)을 사용하겠습니다. 비례 배분에 따른 표본 데이터의 표본 층 크기는 아래와 같습니다.

$$ 
n_h = n\times\frac{N_h}{\sum_{l=1}^HN_l}
$$

`df_all` 데이터의 30%만 샘플링한다고 하겠습니다. 그럴 경우 필요한 층(`bsym`)별 표본 크기(`nh`)는 아래와 같습니다.

```{r}
# 전체 데이터의 30%: 7495개
round(nrow(df_all) * 0.3)

# 모집단 층 크기: Nh, 표본 층 크기: nh
df_target <- df_target %>% 
  mutate(N = nrow(df_all)) %>% 
  mutate(n = round(nrow(df_all) * 0.3)) %>% 
  relocate(count_y, .after = n) %>% 
  rename(Nh = count_y) %>% 
  mutate(nh = round(n*Nh/N)) %>% 
  group_by(bsym)

df_target %>% print(n=25)

# 반올림 때문에 표본 층 크기가 n=7495 보다 1개 더 크므로 
# 2011년 11월 표본 크기를 한 개 줄여주자
df_target$nh[df_target$bsym=='2011-11'] <- df_target$nh[df_target$bsym=='2011-11'] - 1
```

이제 주어진 표본배분안에 따라 `bsym`별 30% 정도의 표본을 뽑아보겠습니다.

```{r}
set.seed(123)
ord <- unique(df_target$bsym)
units <- sampling::strata(df_all, stratanames = "bsym", size = df_target$nh[1:24], method="srswor")

df_all_sample <- df_all %>% 
  slice(units$ID_unit)
df_all_sample %>% dim()
```

이제 층화추출 후 표본 데이터 `df_all_sample`이 기존 모집단 데이터인 `df_all`의 `bsym` 별 `target`의 비율을 유지하는지 확인해 보겠습니다.

```{r}
#| label: tbl-1
#| tbl-cap: "연도 및 월별 재구매 비율: 표본 vs 모집단"
#| code-fold: true
#| warning: false
library(gt)
library(gtExtras)
df_tmp <- df_all_sample %>% 
  group_by(bsym) %>% 
  reframe(sum_y = sum(target),
          nh = n())
   
df_tmp2 <- df_tmp %>% 
  mutate(target_ratio = sum_y/nh,
         target_ratio_pop = df_target$ratio[1:24]) %>% 
  pivot_longer(cols=c(target_ratio, target_ratio_pop), names_to = 'name') %>% 
  group_by(bsym) %>% 
  reframe(target_ratio = list(value))
df_tmp %>% left_join(df_tmp2, by='bsym') %>% 
  gt() %>% 
  gt_theme_nytimes() %>% 
  tab_header(title = "bsym별 target 비율") %>% 
  gt_plt_bar_stack(column = target_ratio, labels = c("target_ratio", "target_ratio_pop"), palette = c("skyblue", "hotpink"))
```

```{r}
# 표본 전체 target ratio: 38.1%
# 모집단 전체 target ratio: 37.5%
df_all_sample$target %>% mean()
df_all$target %>% mean()
```

이렇게 구성한 `df_all_sample` 데이터를 가지고 Data Mart를 만드는 과정을 다음 포스팅에서 다루겠습니다.


