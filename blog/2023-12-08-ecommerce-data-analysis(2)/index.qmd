---
title: "E-commerce 데이터 분석 (2)"
description: |
  Data Mart 구성 및 Feature Engineering
date: 2023-12-08
categories: [machine learning, statistics]
image: ecommerce2.png
preview-links: true
execute: 
  cache: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set()
options(width = 200)
```


본 포스팅은 패스트캠퍼스 [50개 프로젝트로 완벽하게 끝내는 머신러닝 시그니쳐](https://fastcampus.co.kr/data_online_msignature)의 강의내용을 바탕으로 참고하여 작성하였습니다.

앞서 [E-commerce 데이터 분석 (1)](https://gwook.blog/blog/2023-12-03-ecommerce-data-analysis/)에서 A사가 운영하는 이커머스 플랫폼의 ②유입 고객 재구매를 촉진시키기 위해 7단계의 문제해결 프로세스를 정의했으며, Step 5의 데이터 분석 단계에 필요한 과정을 진행했습니다.

# 03. Data Mart & Feature Engineering {#sec-3}

## 03-01. Data Mart 기획 및 설계

![모델링을 위한 Data Mart 기획](data-mart.png)

```{r}
#| echo: false
#| warning: false
#| message: false
pacman::p_load(tidyverse, lubridate, gt, gtExtras)
data <- readRDS("../../_data/e-commerce-data-analysis/part1.rds")
df_origin <- data$df_origin
df_all <- data$df_all
df_all_sample <- data$df_all_sample
df_target <- data$df_target
rm(data)
```

고객 24,983명에 대한 거래 이력이 총 78만 건 정도였고, 이를 고객 데이터셋을 Undersampling 하여 추출한 분석 대상이 7,495명의 고객 데이터인 상황입니다. UCI Machine Learning Repository의 Online Retail 데이터를 Data Warehouse에서 가져온 데이터이고, 이를 이용해 고객별 구매 이력에 대한 Data Mart를 구성하려고 합니다. 이제 여러 가설을 세워 재구매 여부 `target`에 영향을 미치는 여러 변수(features)를 만들어 보겠습니다. 아래는 Data Mart를 구성하는 여러 feature 에 대한 설명과 로직이 작성되어 있는 Data Mart 기획서입니다.

![Data Mart 기획서](data-mart-desc.png){#fig-1 fig-align="center"}

## 03-02. Data 추출 및 Mart 개발

기본적인 전처리가 끝난 후 데이터를 `df_origin`로 저장되어 있습니다. 샘플링한 표본 데이터를 대상으로 Mart를 구성하기 위해서, 우선 `df_origin`과 표본 데이터 `df_all_sample`에 `bsym`과 `CustomerID`를 조합해 key 변수를 만들어 보겠습니다.

```{r}
df_origin %>% head()
df_all_sample %>% head()

# df_origin에 key 변수 생성
df_origin <- df_origin %>% 
  mutate(key = str_c(bsym, CustomerID))
df_origin %>% 
  reframe(n_key = n_distinct(key))

# df_all_sample에 key 변수 생성
df_all_sample <- df_all_sample %>% 
  mutate(key = str_c(bsym, CustomerID))
df_all_sample %>% 
  reframe(n_key = n_distinct(key))
```

이제 `df_origin`의 `key`를 이용해 `df_all_sample`에 존재하는 행들만 가져와 `df_origin_sample` 이라는 데이터를 만듭니다.

```{r}
df_origin_sample <- df_origin %>% 
  filter(key %in% df_all_sample$key)

# df_origin과 df_origin_sample의 비율: 대략 30% 정도
nrow(df_origin_sample)/nrow(df_origin)
```

### Mart 구성 

#### **구매금액**

- Idea: 월별 구매금액에 따라 다음 달 재구매 확률이 다를 것이다

Mart 기획서의 첫 번째 **구매금액** 관련 3개의 변수를 만들기 위해 `StockCode` 당 구매금액을 나타내는 변수 `amt`를 `UnitPrice * Quantity`로 정의하겠습니다.

```{r}
# 1. 구매금액 amt 관련 변수 , max_amt, min_amt
## 1) total_amt: 당월 총 구매금액
df_mart <- df_origin_sample %>%
  mutate(amt = UnitPrice * Quantity) %>% 
  group_by(bsym, CustomerID) %>% 
  reframe(total_amt = sum(amt, na.rm = T))

## 2) max_amt, min_amt: 당월 송장당 최대/최소 구매금액
df_mart <- df_mart %>% left_join(
  df_origin_sample %>% 
  mutate(amt = UnitPrice * Quantity) %>% 
  group_by(bsym, CustomerID, InvoiceNo) %>% 
  reframe(amt = sum(amt, na.rm = T)) %>% 
  group_by(bsym, CustomerID) %>% 
  reframe(max_amt = max(amt, na.rm = T),
          min_amt = min(amt, na.rm = T)),
  by = c("bsym", "CustomerID")
)

df_mart %>% head()
```

#### **구매건수**

- Idea: 월별 구매건수에 따라 다음 달 재구매 확률이 다를 것이다

이제 구매건수(`cnt`)와 관련된 변수 3가지를 만들겠습니다. 월별 총 구매건수는 `total_cnt`로, 월별 송장(`InvoiceNo`)별 구매 품목 수의 최대/최소는 `max_cnt`, `min_cnt`로 정의하겠습니다.

```{r}
# 2. 구매건수 cnt 관련 변수
## 1) total_cnt: 당월 총 구매건수
df_mart <- df_mart %>% left_join(
  df_origin_sample %>% 
  group_by(bsym, CustomerID) %>% 
  reframe(total_cnt = n_distinct(InvoiceNo)),
  by = c("bsym", "CustomerID")
)
## 2) max_cnt, min_cnt: InvoiceNo별 최대/최소 구매 품목 수
df_mart <- df_mart %>% 
  left_join(
    df_origin_sample %>% 
      group_by(bsym, CustomerID, InvoiceNo) %>% 
      reframe(cnt = n_distinct(StockCode)) %>% 
      group_by(bsym, CustomerID) %>% 
      reframe(max_cnt = max(cnt, na.rm = T),
              min_cnt = min(cnt, na.rm = T)),
    by = c("bsym", "CustomerID")
  )


df_mart %>% head()
```

#### **구매수량**


- Idea: 월별 구매수량에 따라 다음 달 재구매 확률이 다를 것이다

```{r}
# 3. 구매수량 qty 관련 변수
## 1) total_qty: 당월 총 구매수량
df_mart <- df_mart %>% left_join(
  df_origin_sample %>% 
    group_by(bsym, CustomerID) %>% 
    reframe(total_qty = sum(Quantity, na.rm = T),
            max_qty = max(Quantity, na.rm = T),
            min_qty = min(Quantity, na.rm = T)),
  by = c("bsym", "CustomerID")
)

df_mart %>% head()
```



#### **국적**

- Idea: 국적에 따라 재구매 확률이 다를 것이다

```{r}
# 4. 국적 변수 생성
df_mart <- df_mart %>% left_join(
  df_origin_sample %>% 
    group_by(bsym, CustomerID) %>% 
    reframe(Country = first(Country)),
  by = c("bsym", "CustomerID")
)
df_mart %>% head()
```

#### **구매 시간대**

- Idea: 구매 시간대(아침, 점심, 저녁, 밤)에 따라 재구매 확률이 다를 것이다

월별 고객별 아침, 점심, 저녁, 밤에 따른 구매 빈도를 구한 후 가장 많은 시간대를 `peak_time`이라는 이름의 feature로 선택하겠습니다.

```{r}
# 5. 구매 시간대(아침, 점심, 저녁, 밤)
## 아침: 6~12시, 점심: 12~18시, 저녁: 18~24시, 밤: 0~6시
## 시간대별 구매 빈도 계산
df_mart <- df_mart %>% left_join(
  df_origin_sample %>% 
    mutate(hour = hour(InvoiceDate),
           peak_time = case_when(
             hour >= 6  & hour < 12 ~ "Morning",
             hour >= 12 & hour < 18 ~ "Afternoon",
             hour >= 18 & hour < 24 ~ "Evening",
             TRUE ~ "Night"
           )) %>% 
    group_by(bsym, CustomerID, peak_time) %>% 
    reframe(purchase_cnt = n()) %>% 
    group_by(bsym, CustomerID) %>% 
    slice_max(purchase_cnt, n = 1, with_ties = FALSE) %>% 
    select(-purchase_cnt) %>% 
    ungroup(),
  by = c("bsym", "CustomerID")
)
df_mart %>% head()
```

#### **계절**

- Idea: 계절에 따라 재구매 확률이 다를 것이다

```{r}
# 6. 계절 변수 추가
df_mart <- df_mart %>% left_join(
  df_origin_sample %>% 
    mutate(month = month(InvoiceDate),
           season = case_when(
             month %in% c(3,4,5) ~ "Spring",
             month %in% c(6,7,8) ~ "Summer",
             month %in% c(9,10,11) ~ "Autumn",
             TRUE ~ "Winter"
           )) %>% 
    group_by(bsym, CustomerID) %>% 
    reframe(season = first(season)),
  by = c("bsym", "CustomerID")
)
df_mart %>% head()
```


#### **구매 빈도**

- Idea: 구매 빈도가 높은 고객은 재구매 확률이 높을 것이다

```{r}
# 7. 당월 구매 빈도
## freq = count(InvoiceNo) / # num of days in month
df_mart <- df_mart %>% left_join(
  df_origin_sample %>% 
    group_by(bsym, CustomerID) %>% 
    reframe(cnt = n_distinct(InvoiceNo)) %>% 
    mutate(
      tmp_date = as.Date(paste0(bsym, "-01")),
      days = as.integer(day(floor_date(tmp_date + months(1), "month") - 1)),
      freq = cnt / days
    ) %>% 
    select(-c(cnt, tmp_date, days)),
  by = c("bsym", "CustomerID")
)

df_mart %>% head()
```

#### **평균 구매금액**

- Idea: 평균 구매금액에 따라 재구매 확률이 다를 것이다

이 변수는 단순히 `total_amt`를 `total_cnt`로 나눈 값입니다.

```{r}
# 8. 평균 구매금액: avg_amt
## 송장당 평균 구매금액
df_mart <- df_mart %>% 
  mutate(avg_amt = total_amt / total_cnt)

df_mart %>% head()
```

이제 `target` 변수와 병합해 저장하겠습니다.

```{r}
df_mart <- df_mart %>% left_join(
  df_all_sample %>% select(-key),
  by = c("bsym", "CustomerID")
)

df_mart %>% head()
df_mart %>% dim()
```


## 03-03. Numeric Feature Engineering

### Feature Engineering

> Feature Enigneering이란?

Feature들을 재구성하여 모델을 효과적으로 사용하기 쉽게 하는 작업을 말합니다. 즉, 모델링의 성능을 향상시키기 위해 feature를 생성, 선택, 가공하는 일련의 모든 활동을 의미합니다. Feature의 주요한 특징들을 잘 나타낼 수 있도록 변수의 변환, encoding 등의 작업들이 포함됩니다. 

때로는 새로운 feature를 생성하기도 하고, 변환(transformation)도 가능합니다. 또한 Feature selection(변수 선택)과 Feature extraction(차원 축소)를 이용하기도 합니다.

현재 저희의 목적은 다음 달 재구매 여부 `target`을 잘 분류하는 모델을 구축하는 Classification 문제에 적합한 feature engineering 과정을 적용하겠습니다.

### Information Value

이진 분류 문제에서 Event(여기서 `target=1`인 경우)와 Non Event의 비율을 고려할 때, 각 비율의 불균형한 정도를 확연하게 보고 싶을 때 사용하는 방법입니다. WoE(Weight of Evidence) 값을 아래와 같이 정의해보겠습니다.

$$ 
\begin{aligned}
\text{WoE} &= \text{log}\frac{p}{1-p}\\
where\quad p &= Pr(Event)
\end{aligned}
$$

즉, WoE는 Event 비율의 Odds 값에 로그를 취한 Logit 값입니다. 어떤 Feature의 각 구간(bin)에 대한 (범주형일 경우 각 level) 정보 가치 값은 $$IV_i = (Event_i\% - NonEvent_i\%)\times WoE_i$$으로 표현할 수 있고, 해당 Feature의 정보가치는 이를 모두 더한 $$IV = \sum IV_i = \sum\{(Event_i\% - NonEvent_i\%)\times WoE_i\}$$ 으로 정의할 수 있습니다.

이러한 feature 별 IV 값에 대한 통상적인 기준은 아래와 같습니다.

![IV 값에 따른 예측력](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FsqkdV%2Fbtr8wPiFwWb%2FB7ugBV1LB50Rjgm6tfU9tK%2Fimg.jpg)

자세한 내용은 [Logistic 예측 모형에서의 변수 선택 방법 - Information Value](https://recipesds.tistory.com/entry/Logistic-%EC%98%88%EC%B8%A1-%EB%AA%A8%ED%98%95%EC%97%90%EC%84%9C%EC%9D%98-%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D-%EB%B0%A9%EB%B2%95-Information-Value)을 참고하시면 됩니다.

이제 앞서 구성한 Data Mart(`df_mart`)의 각 feature에 대해서 IV 값을 구해보겠습니다.

```{r}
df_mart %>% 
  reframe(across(everything(), typeof))
```

우선 수치형 변수들에 대해 각각 5% 단위로 binning을 해주고, 40%, 75% 백분위수를 기준으로 3개의 그룹으로 구간화를 시켜주겠습니다.

```{r}
iv_calculate <- function(data, var){
  quant <- quantile(data[[var]], probs = c(0.40, 0.75))
  iv <- data %>% 
    mutate(grp = findInterval(.data[[var]], quant, rightmost.closed = T) + 1,
           n_target = ifelse(target==1, 0, 1)) %>% 
    group_by(grp) %>% 
    reframe(
      target = sum(target, na.rm = T),
      n_target = sum(n_target, na.rm = T)
    ) %>% 
    mutate(
      good_pct = target / sum(target),
      bad_pct = n_target / sum(n_target),
      t_ratio = target / (target + n_target),
      VAR = var,
      iv = (good_pct - bad_pct) * log(good_pct / bad_pct)
    ) 
  return(iv)
}

numeric_cols <- df_mart %>% select_if(is.numeric) %>% select(-target) %>% colnames()

iv_df <- map_dfr(numeric_cols, ~ iv_calculate(df_mart, .x))
print(iv_df, n = nrow(iv_df))

# Feature 별 IV 값 합산
iv_df %>% 
  group_by(VAR) %>% 
  reframe(iv = sum(iv)) %>% 
  arrange(desc(iv))
```

수치형 변수들에 대해서 이렇게 직접 구간(bin)의 경계값을 지정해서 binning을 할 수 있습니다. 이번에는 `target` 변수를 잘 예측하는, 즉 변수별 IV 값이 높게 나오도록 구간화를 하는 방법을 소개하겠습니다. 이러한 방법을 optimized binning이라고 합니다.

`dlookr` 패키지의 `binning_by()` 함수는 반응변수(`target`)을 가장 잘 예측하는 경계값으로 수치형 변수를 binning 하기 때문에 변수별로 bin의 개수가 다를 수 있으며, 수치형 변수가 `target`과 유의한 관계가 없는 경우 구간화를 하지 않아서 변수 선택을 고려할 수도 있습니다.

```{r}
library(dlookr)
numeric_cols <- df_mart %>% select_if(is.numeric) %>% select(-target) %>% colnames()

# binning_by() 이용 시 target과 유의하지 않은 변수는 구간화를 하지 않음
bin_process <- function(data, var){
  tryCatch({
    bin <- binning_by(data, target, var)
    attr(bin, "name") <- var
    return(bin)
  }, warning = function(w){
    bin <- "No significant splits"
    attr(bin, "name") <- var
    return(bin)
  }, error = function(e){
    bin <- "Error"
    attr(bin, "name") <- var
    return(bin)
  })
}

bin_list <- map(numeric_cols, ~bin_process(df_mart, .x))
```

```{r}
#| echo: false

# 이상하게 첫 번째 total_amt가 계속 유의하지 않다고 들어가서 
# 한 번 더 돌려주는 코드 작성
bin_list <- map(numeric_cols, ~bin_process(df_mart, .x))
```

```{r}
# target과 유의하지 않은 변수 확인:
bin_list %>% 
  keep(~typeof(.x) == "character") %>% 
  map(~attr(.x, "name")) %>% 
  unlist()
```

앞서 40%, 75% 백분위수 값을 경계로 IV 값을 구했 때 가장 낮은 IV 값을 가졌던 `min_amt`와 `min_qty`는 최적 구간으로 IV 값을 구했을 경우에도 `target`과 유의하지 않다고 판단되므로 고려하지 않겠습니다.

Optimized binning이 각 수치형 변수의 몇 % 백분위수를 bin의 경계값으로 삼는지 확인해 보겠습니다.

```{r}
bin_cutoff <- function(data, bin){
  # cutoff level 
  cutoff <- attr(bin, "breaks")
  grp <- c()
  for(i in 1:(length(cutoff)-1)){
    if(i==1){
      brk <- paste0("[", cutoff[i], ",", cutoff[i+1], "]")
    } else{
      brk <- paste0("(", cutoff[i], ",", cutoff[i+1], "]")
    }
    grp <- c(grp, brk)
  }
  attr(bin, "levels") <- grp
  # data의 수치형변수에서 해당 cutoff가 몇% 백분위수 인지
  value <- cutoff[2:(length(cutoff)-1)]
  ecdf_func <- ecdf(data[[attr(bin, "name")]])
  percentile <- ecdf_func(value)
  return(data.frame(Var = attr(bin, "name"), 
                    cutoff = value,
                    percentile = scales::percent(percentile, accuracy = 2)))
}

sig_bin_list <- bin_list %>% 
  keep(~typeof(.x) == "integer")

# Optimized bin의 경계값 분위수 확인
sig_bin_list %>% 
  map(~bin_cutoff(df_mart, .x)) 

# Optimized binning 후 IV 값 확인
sig_bin_list %>% 
  map(~data.frame(name = attr(.x, "name"),
                  IV = attr(.x, "performance") %>% pull(IV) %>% .[length(.)])) %>% 
  list_rbind() %>% 
  arrange(desc(IV))
```

낮은 IV 값을 가졌던 `min_qty`와 `min_amt`를 제외하고 비교해보면, 직접 구간화를 했을 때보다 전반적으로 IV 값들이 높아졌습니다.

Binning 후 각 구간의 분포와 `target`이 1일 때의 분포 그래프를 확인할 수도 있습니다. 아래는 `total_cnt`의 최적 구간화 이후 각 구간별 분포와, `target`이 1인 것의 분포를 나타냅니다.

```{r}
#| label: fig-2
#| fig-cap: "total_cnt binning 후 분포"
#| code-fold: true
library(patchwork)
total_cnt_bin <- sig_bin_list %>% 
  keep(~attr(.x, "name") == "total_cnt") %>% .[[1]] 
p1 <- total_cnt_bin %>% plot(type = "freq") +
  theme(legend.position = "none")
p2 <- total_cnt_bin %>% plot(type = "posrate") +
  theme(legend.position = "none")
p1 + p2
```


## 03-03. Categorical Feature Engineering

범주형 변수인 `Country`, `peak_time`, `season`에 대해서도 IV 값을 구해서 `target` 변수와의 관계를 살펴보겠습니다.

우선 국적 변수인 `Country`에 대해 살펴보겠습니다.

```{r}
# 국적 Country 변수 unique한 값 수
df_mart %>% 
  reframe(n_uniq = n_distinct(Country))
```

```{r}
#| label: fig-3
#| fig-cap: "국적별 target 분포"
#| code-fold: true
df_mart %>% 
  ggplot(aes(x=Country, fill = factor(target))) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  coord_flip() +
  labs(fill = "Target", x = "Country", y = "Count")
```


@fig-3 을 보면 `Country` 변수의 대부분이 영국(United Kingdom)임을 알 수 있습니다. 따라서 영국을 제외한 나머지 값들은 기타 국가로 변경하겠습니다.

```{r}
df_mart %>% 
  count(Country) %>% 
  arrange(desc(n)) %>% 
  mutate(ratio = n/sum(n))

# UK 이외의 기타 국가로 처리
df_mart <- df_mart %>% 
  mutate(Country = ifelse(Country=="United Kingdom", "UK", "ETC")) 
```

이제 범주형 변수인 `Country`, `peak_time`, `season`의 IV 값을 구해보겠습니다.

```{r}
#| warning: false
library(scorecard)
Country_iv <- woebin(df_mart, "target", "Country")
peak_iv <- woebin(df_mart, "target", "peak_time")
season_iv <- woebin(df_mart, "target", "season")

# Country IV 
Country_iv$Country %>% tibble()

# peak_time IV
peak_iv$peak_time %>% tibble()

# season IV
season_iv$season %>% tibble()
```

`target` 변수에 대한 범주형 변수들의 IV 값을 보면 굉장히 낮으므로 이 세 변수는 `target` 변수와 유의미한 관계가 없어 보입니다. 


